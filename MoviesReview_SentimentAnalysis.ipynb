{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guidelines\n",
    "- Use any machine learning algorithms except deep learning.\n",
    "- \"1. Dataset preparation\" and \"2. Feature Engineering and Model Building\" sections are provided. Note that the \"2. Feature Engineering and Model Building\" section is provided only for your reference, i.e. as a baseline model and performance.\n",
    "- In general, try to build the best model that provides the best performance results (especially accuracy and f1-score) using various techniques (such as feature engineering and parameter tunning) you have learnt from the class so far. \n",
    "- Make sure that you measure accuracy and f1_score with the test_data and test_labels generated in \"1. Dataset preparation\" section. In other words, every one will use the same test dataset.\n",
    "- Discuss the results based on your observation (use comments or Markdown cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries for dataset preparation, feature engineering, model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "# install textblob: $>pip install textblob\n",
    "import xgboost, numpy, textblob, string  \n",
    "import nltk\n",
    "\n",
    "# load functions from textpreprocess.py\n",
    "from textpreprocess import denoise_text, normalize, replace_contractions, remove_non_ascii, to_lowercase, remove_punctuation, replace_numbers, remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation\n",
    "We are using a movie review dataset. The dataset consists of 2,000 reviews and their labels. 90% of the reviews are stored into train_data, and 10% of them into test_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data_dir = 'data'\n",
    "    classes = ['pos', 'neg']\n",
    "\n",
    "    # Step1 - Read the data\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    for curr_class in classes:\n",
    "        dirname = 'data/'+curr_class\n",
    "        for fname in os.listdir(dirname):\n",
    "            with open(os.path.join(dirname, fname), 'r') as f:\n",
    "                content = f.read()\n",
    "                # Partition the test data\n",
    "                if fname.startswith('cv9'):\n",
    "                    test_data.append(content)\n",
    "                    test_labels.append(curr_class)\n",
    "                else:\n",
    "                    train_data.append(content)\n",
    "                    train_labels.append(curr_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.count('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 TF-IDF Vectors as features\n",
    "\n",
    "Apart from the basic tf-idf with predefined min_df=5 and max_df=0.8, Stop_words is also included to observe the performance. I also added the following 3 levels of input tokens to observe the performance.\n",
    "\n",
    "a. Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n",
    "\n",
    "b. N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
    "\n",
    "c. Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tf-idf without stop words\n",
    "tfidf_vect = TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)\n",
    "xtrain_tfidf =  tfidf_vect.fit_transform(train_data)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_data)\n",
    "\n",
    "# Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "tfidf_stopw_vect = TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True, stop_words='english')\n",
    "xtrain_tfidf_stopw =  tfidf_stopw_vect.fit_transform(train_data)\n",
    "xtest_tfidf_stopw =  tfidf_stopw_vect.transform(test_data)\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_word_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000, stop_words='english', sublinear_tf=True)\n",
    "xtrain_tfidf_word =  tfidf_word_vect.fit_transform(train_data)\n",
    "xtest_tfidf_word =  tfidf_word_vect.transform(test_data)\n",
    "\n",
    "# ngram level tf-idf\n",
    "tfidf_ngram_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000, stop_words='english', sublinear_tf=True)\n",
    "xtrain_tfidf_ngram =  tfidf_ngram_vect.fit_transform(train_data)\n",
    "xtest_tfidf_ngram =  tfidf_ngram_vect.transform(test_data)\n",
    "\n",
    "# characters level tf-idf\n",
    "# Regular expression denoting what constitutes a \"token\", only used if analyzer == 'word'\n",
    "tfidf_chars_vect = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000, stop_words='english', sublinear_tf=True)\n",
    "xtrain_tfidf_chars =  tfidf_chars_vect.fit_transform(train_data)\n",
    "xtest_tfidf_chars =  tfidf_chars_vect.transform(test_data)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count Vectors as features\n",
    "\n",
    "[Count Vector](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object: \n",
    "# analyzer: whether the feature should be made of word or character n-grams.\n",
    "# token_pattern: regular expression denoting what constitutes a “token”\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "\n",
    "# fit and transform the training and test data using count vectorizer object\n",
    "xtrain_count =  count_vect.fit_transform(train_data)\n",
    "xtest_count =  count_vect.transform(test_data) # just transform test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building\n",
    "The next step in the text classification framework is to train a classifier using the features created in the previous step. There are many different choices of machine learning models which can be used to train a final model. We will implement Naive Bayes Classifier for this purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a utility function which can be used to train a model. It accepts the classifier, feature_vector of training data, labels of training data and feature vectors of valid data as inputs. Using these inputs, the model is trained. Then, Accuracy score is computed and the classification report is obtained which gives us the precision, recall, f1-score and accuracy.\n",
    "\n",
    "Precision: $\\frac{TP}{TP + FP}$\n",
    "\n",
    "Recall: $\\frac{TP}{TP + FN}$\n",
    "\n",
    "F1-Score: $\\frac{2 * (precision * recall)}{precision + recall}$ <br>\n",
    "<i>The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.</i>\n",
    "\n",
    "Accuracy: $\\frac{Number of correct predictions}{Total number of predictions}$ or $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "<p>\n",
    "\n",
    "<i>Notes:</i><br>\n",
    "TP: True Positive <br>\n",
    "FP: False Positive <br>\n",
    "TN: True Negative <br>\n",
    "FN: False Negative <p>\n",
    "\n",
    "<i>References:</i><br>\n",
    "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall <br>\n",
    "https://developers.google.com/machine-learning/crash-course/classification/accuracy <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "     \n",
    "    return metrics.accuracy_score(predictions, test_labels), classification_report(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Naive Bayes Classifier\n",
    "Implementing a naive bayes model using sklearn implementation with different features\n",
    "\n",
    "[Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. A Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature here ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for Basic TF-IDF without stop words:  0.85\n",
      "NB, Report for Basic TF-IDF without stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.92      0.86       100\n",
      "         pos       0.91      0.78      0.84       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.86      0.85      0.85       200\n",
      "weighted avg       0.86      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Basic tf-idf without stop words\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_labels, xtest_tfidf)\n",
    "print (\"NB, Accuracy for Basic TF-IDF without stop words: \", accuracy)\n",
    "print (\"NB, Report for Basic TF-IDF without stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for Basic TF-IDF with stop words:  0.85\n",
      "NB, Report for Basic TF-IDF with stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.90      0.86       100\n",
      "         pos       0.89      0.80      0.84       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.85      0.85       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_stopw, train_labels, xtest_tfidf_stopw)\n",
    "print (\"NB, Accuracy for Basic TF-IDF with stop words: \", accuracy)\n",
    "print (\"NB, Report for Basic TF-IDF with stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for WordLevel TF-IDF:  0.83\n",
      "NB, Report for WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.89      0.84       100\n",
      "         pos       0.88      0.77      0.82       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.83      0.83      0.83       200\n",
      "weighted avg       0.83      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_word, train_labels, xtest_tfidf_word)\n",
    "print (\"NB, Accuracy for WordLevel TF-IDF: \", accuracy)\n",
    "print (\"NB, Report for WordLevel TF-IDF:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for N-Gram Vectors:  0.77\n",
      "NB, Report for N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.82      0.78       100\n",
      "         pos       0.80      0.72      0.76       100\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.77       200\n",
      "weighted avg       0.77      0.77      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_labels, xtest_tfidf_ngram)\n",
    "print (\"NB, Accuracy for N-Gram Vectors: \", accuracy)\n",
    "print (\"NB, Report for N-Gram Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for CharLevel Vectors:  0.79\n",
      "NB, Report for CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.83      0.80       100\n",
      "         pos       0.82      0.75      0.78       100\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_chars, train_labels, xtest_tfidf_chars)\n",
    "print (\"NB, Accuracy for CharLevel Vectors: \", accuracy)\n",
    "print (\"NB, Report for CharLevel Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Accuracy for Count Vectors:  0.83\n",
      "NB, Report for Count Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.87      0.84       100\n",
      "         pos       0.86      0.79      0.82       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.83      0.83      0.83       200\n",
      "weighted avg       0.83      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "# train_model(classifier, train feature vectors (countvectorizer, label, \n",
    "# validation feature vectors(countvectorizer))\n",
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_labels, xtest_count)\n",
    "print (\"NB, Accuracy for Count Vectors: \", accuracy)\n",
    "print (\"NB, Report for Count Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Logistic Regression\n",
    "\n",
    "Implementing a Linear Classifier (Logistic Regression)\n",
    "\n",
    "[Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic/sigmoid function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for Basic TF-IDF without stop words:  0.895\n",
      "LR, Report for Basic TF-IDF without stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.90      0.90       100\n",
      "         pos       0.90      0.89      0.89       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.89       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Basic tf-idf without stop words\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_labels, xtest_tfidf)\n",
    "print (\"LR, Accuracy for Basic TF-IDF without stop words: \", accuracy)\n",
    "print (\"LR, Report for Basic TF-IDF without stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for Basic TF-IDF with stop words:  0.885\n",
      "LR, Report for Basic TF-IDF with stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.93      0.89       100\n",
      "         pos       0.92      0.84      0.88       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_stopw, train_labels, xtest_tfidf_stopw)\n",
    "print (\"LR, Accuracy for Basic TF-IDF with stop words: \", accuracy)\n",
    "print (\"LR, Report for Basic TF-IDF with stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for WordLevel TF-IDF:  0.875\n",
      "LR, Report for WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.89      0.88       100\n",
      "         pos       0.89      0.86      0.87       100\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.87       200\n",
      "weighted avg       0.88      0.88      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_word, train_labels, xtest_tfidf_word)\n",
    "print (\"LR, Accuracy for WordLevel TF-IDF: \", accuracy)\n",
    "print (\"LR, Report for WordLevel TF-IDF:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for N-Gram Vectors:  0.795\n",
      "LR, Report for N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.85      0.81       100\n",
      "         pos       0.83      0.74      0.78       100\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.79      0.79       200\n",
      "weighted avg       0.80      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_labels, xtest_tfidf_ngram)\n",
    "print (\"LR, Accuracy for N-Gram Vectors: \", accuracy)\n",
    "print (\"LR, Report for N-Gram Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for CharLevel Vectors:  0.845\n",
      "LR, Report for CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.84      0.84       100\n",
      "         pos       0.84      0.85      0.85       100\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.84      0.84       200\n",
      "weighted avg       0.85      0.84      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_tfidf_chars, train_labels, xtest_tfidf_chars)\n",
    "print (\"LR, Accuracy for CharLevel Vectors: \", accuracy)\n",
    "print (\"LR, Report for CharLevel Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Accuracy for Count Vectors:  0.855\n",
      "LR, Report for Count Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.86      0.86       100\n",
      "         pos       0.86      0.85      0.85       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.86      0.85      0.85       200\n",
      "weighted avg       0.86      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "# train_model(classifier, train feature vectors (countvectorizer, label, \n",
    "# validation feature vectors(countvectorizer))\n",
    "accuracy, report = train_model(linear_model.LogisticRegression(), xtrain_count, train_labels, xtest_count)\n",
    "print (\"LR, Accuracy for Count Vectors: \", accuracy)\n",
    "print (\"LR, Report for Count Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM Classifer\n",
    "\n",
    "[Support Vector Machine (SVM)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) is a supervised machine learning algorithm which can be used for both classification or regression challenges. The model extracts a best possible hyper-plane / line that segregates the two classes. \n",
    "\n",
    "The implementation of SVM is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\n",
    "The multiclass support is handled according to a one-vs-one scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for Basic TF-IDF without stop words:  0.915\n",
      "SVM, Report for Basic TF-IDF without stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.91      0.92      0.92       100\n",
      "         pos       0.92      0.91      0.91       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.91       200\n",
      "weighted avg       0.92      0.92      0.91       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Basic tf-idf without stop words\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_tfidf, train_labels, xtest_tfidf)\n",
    "print (\"SVM, Accuracy for Basic TF-IDF without stop words: \", accuracy)\n",
    "print (\"SVM, Report for Basic TF-IDF without stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for Basic TF-IDF with stop words:  0.885\n",
      "SVM, Report for Basic TF-IDF with stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.87      0.90      0.89       100\n",
      "         pos       0.90      0.87      0.88       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_tfidf_stopw, train_labels, xtest_tfidf_stopw)\n",
    "print (\"SVM, Accuracy for Basic TF-IDF with stop words: \", accuracy)\n",
    "print (\"SVM, Report for Basic TF-IDF with stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for WordLevel TF-IDF:  0.895\n",
      "SVM, Report for WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.89      0.89       100\n",
      "         pos       0.89      0.90      0.90       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.89       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Word Level TF IDF Vectors\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_tfidf_word, train_labels, xtest_tfidf_word)\n",
    "print (\"SVM, Accuracy for WordLevel TF-IDF: \", accuracy)\n",
    "print (\"SVM, Report for WordLevel TF-IDF:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for N-Gram Vectors:  0.8\n",
      "SVM, Report for N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.83      0.81       100\n",
      "         pos       0.82      0.77      0.79       100\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.80       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_tfidf_ngram, train_labels, xtest_tfidf_ngram)\n",
    "print (\"SVM, Accuracy for N-Gram Vectors: \", accuracy)\n",
    "print (\"SVM, Report for N-Gram Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for CharLevel Vectors:  0.87\n",
      "SVM, Report for CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.86      0.87       100\n",
      "         pos       0.86      0.88      0.87       100\n",
      "\n",
      "    accuracy                           0.87       200\n",
      "   macro avg       0.87      0.87      0.87       200\n",
      "weighted avg       0.87      0.87      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Character Level TF IDF Vectors\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_tfidf_chars, train_labels, xtest_tfidf_chars)\n",
    "print (\"SVM, Accuracy for CharLevel Vectors: \", accuracy)\n",
    "print (\"SVM, Report for CharLevel Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy for Count Vectors:  0.835\n",
      "SVM, Report for Count Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.83      0.83       100\n",
      "         pos       0.83      0.84      0.84       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.84      0.83      0.83       200\n",
      "weighted avg       0.84      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier on Count Vectors\n",
    "# train_model(classifier, train feature vectors (countvectorizer, label, \n",
    "# validation feature vectors(countvectorizer))\n",
    "accuracy, report = train_model(svm.SVC(kernel='linear'), xtrain_count, train_labels, xtest_count)\n",
    "print (\"SVM, Accuracy for Count Vectors: \", accuracy)\n",
    "print (\"SVM, Report for Count Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest Classifier\n",
    "\n",
    "Implementing a [Random Forest Model](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "Random Forest models are a type of ensemble models, particularly bagging models. They are part of the tree based model family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for Basic TF-IDF without stop words:  0.81\n",
      "RF, Report for Basic TF-IDF without stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.90      0.83       100\n",
      "         pos       0.88      0.72      0.79       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Basic tf-idf without stop words\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf, train_labels, xtest_tfidf)\n",
    "print (\"RF, Accuracy for Basic TF-IDF without stop words: \", accuracy)\n",
    "print (\"RF, Report for Basic TF-IDF without stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for Basic TF-IDF with stop words:  0.825\n",
      "RF, Report for Basic TF-IDF with stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.87      0.83       100\n",
      "         pos       0.86      0.78      0.82       100\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.82      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_stopw, train_labels, xtest_tfidf_stopw)\n",
    "print (\"RF, Accuracy for Basic TF-IDF with stop words: \", accuracy)\n",
    "print (\"RF, Report for Basic TF-IDF with stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for WordLevel TF-IDF:  0.815\n",
      "RF, Report for WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.88      0.83       100\n",
      "         pos       0.86      0.75      0.80       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Word Level TF IDF Vectors\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_word, train_labels, xtest_tfidf_word)\n",
    "print (\"RF, Accuracy for WordLevel TF-IDF: \", accuracy)\n",
    "print (\"RF, Report for WordLevel TF-IDF:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for N-Gram Vectors:  0.68\n",
      "RF, Report for N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.67      0.71      0.69       100\n",
      "         pos       0.69      0.65      0.67       100\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_ngram, train_labels, xtest_tfidf_ngram)\n",
    "print (\"RF, Accuracy for N-Gram Vectors: \", accuracy)\n",
    "print (\"RF, Report for N-Gram Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for CharLevel Vectors:  0.74\n",
      "RF, Report for CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.73      0.76      0.75       100\n",
      "         pos       0.75      0.72      0.73       100\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.74      0.74      0.74       200\n",
      "weighted avg       0.74      0.74      0.74       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Character Level TF IDF Vectors\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_tfidf_chars, train_labels, xtest_tfidf_chars)\n",
    "print (\"RF, Accuracy for CharLevel Vectors: \", accuracy)\n",
    "print (\"RF, Report for CharLevel Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Accuracy for Count Vectors:  0.83\n",
      "RF, Report for Count Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.84      0.83       100\n",
      "         pos       0.84      0.82      0.83       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.83      0.83      0.83       200\n",
      "weighted avg       0.83      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF Classifier on Count Vectors\n",
    "# train_model(classifier, train feature vectors (countvectorizer, label, \n",
    "# validation feature vectors(countvectorizer))\n",
    "accuracy, report = train_model(ensemble.RandomForestClassifier(n_estimators=100), xtrain_count, train_labels, xtest_count)\n",
    "print (\"RF, Accuracy for Count Vectors: \", accuracy)\n",
    "print (\"RF, Report for Count Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Boosting Model\n",
    "\n",
    "Implementing [Xtereme Gradient Boosting Model](https://xgboost.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "Boosting models are another type of ensemble models part of tree based models. Boosting is a machine learning ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones. A weak learner is defined to be a classifier that is only slightly correlated with the true classification (it can label examples better than random guessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for Basic TF-IDF without stop words:  0.805\n",
      "Xgb, Report for Basic TF-IDF without stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.77      0.80       100\n",
      "         pos       0.79      0.84      0.81       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.80      0.80       200\n",
      "weighted avg       0.81      0.81      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Basic tf-idf without stop words\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_tfidf, train_labels, xtest_tfidf)\n",
    "print (\"Xgb, Accuracy for Basic TF-IDF without stop words: \", accuracy)\n",
    "print (\"Xgb, Report for Basic TF-IDF without stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for Basic TF-IDF with stop words:  0.835\n",
      "Xgb, Report for Basic TF-IDF with stop words:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.80      0.83       100\n",
      "         pos       0.81      0.87      0.84       100\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.84      0.83      0.83       200\n",
      "weighted avg       0.84      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Extreme Gradient Boosting  on Basic tf-idf with stop words\n",
    "# to remove words that are uninformative in representating the content of the text\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_tfidf_stopw, train_labels, xtest_tfidf_stopw)\n",
    "print (\"Xgb, Accuracy for Basic TF-IDF with stop words: \", accuracy)\n",
    "print (\"Xgb, Report for Basic TF-IDF with stop words:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for WordLevel TF-IDF:  0.815\n",
      "Xgb, Report for WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.80      0.81       100\n",
      "         pos       0.81      0.83      0.82       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_tfidf_word, train_labels, xtest_tfidf_word)\n",
    "print (\"Xgb, Accuracy for WordLevel TF-IDF: \", accuracy)\n",
    "print (\"Xgb, Report for WordLevel TF-IDF:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for N-Gram Vectors:  0.665\n",
      "Xgb, Report for N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.68      0.63      0.65       100\n",
      "         pos       0.65      0.70      0.68       100\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.67      0.67      0.66       200\n",
      "weighted avg       0.67      0.67      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Extreme Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram, train_labels, xtest_tfidf_ngram)\n",
    "print (\"Xgb, Accuracy for N-Gram Vectors: \", accuracy)\n",
    "print (\"Xgb, Report for N-Gram Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for CharLevel Vectors:  0.79\n",
      "Xgb, Report for CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.80      0.79       100\n",
      "         pos       0.80      0.78      0.79       100\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting  on Character Level TF IDF Vectors\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_tfidf_chars, train_labels, xtest_tfidf_chars)\n",
    "print (\"Xgb, Accuracy for CharLevel Vectors: \", accuracy)\n",
    "print (\"Xgb, Report for CharLevel Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Accuracy for Count Vectors:  0.795\n",
      "Xgb, Report for Count Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.74      0.78       100\n",
      "         pos       0.77      0.85      0.81       100\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.79      0.79       200\n",
      "weighted avg       0.80      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting  on Count Vectors\n",
    "# train_model(classifier, train feature vectors (countvectorizer, label, \n",
    "# validation feature vectors(countvectorizer))\n",
    "accuracy, report = train_model(xgboost.XGBClassifier(), xtrain_count, train_labels, xtest_count)\n",
    "print (\"Xgb, Accuracy for Count Vectors: \", accuracy)\n",
    "print (\"Xgb, Report for Count Vectors:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Conclusion\n",
    "I have used 5 types of classifier models on our datasets by training 90% of the data and testing 10% of the data using the trained model. 5 different vectors are used, i.e. <br>\n",
    "<ol>\n",
    "    <li>Basic tf-idf without stop words</li>\n",
    "    <li>Basic tf-idf without stop words</li>\n",
    "    <li>Basic tf-idf with stop words</li>\n",
    "    <li>word level tf-idf</li>\n",
    "    <li>ngram level tf-idf</li>\n",
    "    <li>characters level tf-idf</li>\n",
    "</ol>\n",
    "Based on accuracy and fl-score, after running the trained model with different vectors, the following is the summary of the models with their respective vectors giving the best performance (in the order of best performance first).<br>\n",
    "<ol>\n",
    "    <li>Support Vector Machine with Basic TF-IDF without stop words - Accurary: 0.92, F1-score: 0.91</li>\n",
    "    <li>Linear Regression with Basic TF-IDF without stop words - Accuracy: 0.90, F1-score: 0.90</li>\n",
    "    <li>Naives Bayes with Basic TF-IDF without stop words - Accuracy: 0.85, F1-Score: 0.85</li>\n",
    "    <li>Extreme Gradient Boosting with Basic TF-IDF with stop words - Accuracy: 0.835, F1-Score: 0.83</li>\n",
    "    <li>Random Forest Classifier with Count Vectors - Accuracy: 0.83, F1-Score: 0.83</li>\n",
    "</ol>\n",
    "Overall, SVM provides the best performance. Amongst the vectors, most of the classifiers work best with Basic TF-IDF without stop words except Extreme Gradient Boosting which works best with Basic TF-IDF with stop words and Random Forest Classifier which works best with Count Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid Search with Pipeline - improve performance through grid search of parameters\n",
    "\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) performs exhaustive search over specified parameter values for an estimator.\n",
    "Important members are fit, predict.\n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
    "\n",
    "Based on the results in <b>3 Model Building</b>, Grid Search with Pipeline will be applied to each model with their respective best vectors, i.e. the ones giving the best accuracy. <br>\n",
    "GridSearchCV on Naive Bayes is simpler as it does not have many hyperparameters to tune. <p>\n",
    "    \n",
    "    1. SVM Classifier on Basic tf-idf without stop words<br>\n",
    "    2. Linear Classifier on Basic tf-idf without stop words<br>\n",
    "    3. Extreme Gradient Boosting  on Basic tf-idf with stop words<br>\n",
    "    4. Naive Bayes on Basic tf-idf without stop words<br>\n",
    "    5. RF Classifier on Basic tf-idf without stop words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Grid Search with SVM on Basic tf-idf without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search with SVM:\n",
      "\n",
      "Best score: 0.872\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__gamma: 0.5\n",
      "\tclf__kernel: 'rbf'\n",
      "Accuracy: 0.93\n",
      "Precision: 0.9387755102040817\n",
      "Recall: 0.92\n",
      "F1_score: 0.9292929292929293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)),\n",
    "    ('clf', svm.SVC(kernel='linear'))\n",
    "])\n",
    "parameters = {\n",
    "    'clf__C': (0.01, 1, 10),\n",
    "    'clf__gamma': (0.5, 1,2,3,4),\n",
    "    'clf__kernel': ('rbf', 'linear')\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    print(\"Grid Search with SVM:\\n\")\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    # Refit an estimator using the best found parameters on the whole dataset.\n",
    "    # The refitted estimator is made available at the best_estimator_attribute and \n",
    "    # permits using predict directly on this GridSearchCV instance.\n",
    "    predictions = grid_search.predict(test_data)\n",
    "    print('Accuracy:', accuracy_score(test_labels, predictions))\n",
    "    print('Precision:', precision_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('Recall:', recall_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('F1_score:', f1_score(test_labels, predictions, pos_label='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Grid Search with LinearClassifier on Basic tf-idf without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   21.8s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search with LinearCLassifier:\n",
      "\n",
      "Best score: 0.874\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "Accuracy: 0.92\n",
      "Precision: 0.9375\n",
      "Recall: 0.9\n",
      "F1_score: 0.9183673469387755\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)),\n",
    "    ('clf', linear_model.LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    " 'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    print(\"Grid Search with LinearCLassifier:\\n\")\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    # Refit an estimator using the best found parameters on the whole dataset.\n",
    "    # The refitted estimator is made available at the best_estimator_attribute and \n",
    "    # permits using predict directly on this GridSearchCV instance.\n",
    "    predictions = grid_search.predict(test_data)\n",
    "    print('Accuracy:', accuracy_score(test_labels, predictions))\n",
    "    print('Precision:', precision_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('Recall:', recall_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('F1_score:', f1_score(test_labels, predictions, pos_label='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Grid Search with Extreme Gradient Boosting  on Basic tf-idf with stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search with XGBClassifier:\n",
      "\n",
      "Best score: 0.817\n",
      "Best parameters set:\n",
      "\tclf__learning_rate: 0.1\n",
      "\tclf__max_depth: 3\n",
      "\tclf__n_estimators: 220\n",
      "Accuracy: 0.83\n",
      "Precision: 0.8055555555555556\n",
      "Recall: 0.87\n",
      "F1_score: 0.8365384615384616\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)),\n",
    "    ('clf', xgboost.XGBClassifier())\n",
    "])\n",
    "parameters = {\n",
    "    'clf__max_depth': (2, 3, 5),\n",
    "    'clf__n_estimators': (60, 100, 220),\n",
    "    'clf__learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    print(\"Grid Search with XGBClassifier:\\n\")\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    # Refit an estimator using the best found parameters on the whole dataset.\n",
    "    # The refitted estimator is made available at the best_estimator_attribute and \n",
    "    # permits using predict directly on this GridSearchCV instance.\n",
    "    predictions = grid_search.predict(test_data)\n",
    "    print('Accuracy:', accuracy_score(test_labels, predictions))\n",
    "    print('Precision:', precision_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('Recall:', recall_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('F1_score:', f1_score(test_labels, predictions, pos_label='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Grid Search with Naive Bayes on Basic tf-idf without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   18.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search with GridSearch:\n",
      "\n",
      "Best score: 0.832\n",
      "Best parameters set:\n",
      "\tclf__alpha: 2.0\n",
      "\tclf__fit_prior: True\n",
      "Accuracy: 0.855\n",
      "Precision: 0.9176470588235294\n",
      "Recall: 0.78\n",
      "F1_score: 0.8432432432432432\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)),\n",
    "    ('clf', naive_bayes.MultinomialNB())\n",
    "])\n",
    "parameters = {\n",
    "    'clf__alpha': (0, 1.0, 2.0),\n",
    "    'clf__fit_prior': (True, False)\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    print(\"Grid Search with Naive Bayes:\\n\")\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    # Refit an estimator using the best found parameters on the whole dataset.\n",
    "    # The refitted estimator is made available at the best_estimator_attribute and \n",
    "    # permits using predict directly on this GridSearchCV instance.\n",
    "    predictions = grid_search.predict(test_data)\n",
    "    print('Accuracy:', accuracy_score(test_labels, predictions))\n",
    "    print('Precision:', precision_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('Recall:', recall_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('F1_score:', f1_score(test_labels, predictions, pos_label='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Grid Search with RF Classifier on Basic tf-idf without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search with RandomForest:\n",
      "\n",
      "Best score: 0.797\n",
      "Best parameters set:\n",
      "\tclf__max_depth: None\n",
      "\tclf__max_leaf_nodes: None\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 0.3\n",
      "\tclf__n_estimators: 100\n",
      "Accuracy: 0.82\n",
      "Precision: 0.82\n",
      "Recall: 0.82\n",
      "F1_score: 0.82\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf=True)),\n",
    "    ('clf', ensemble.RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "parameters = {\n",
    "    \"clf__n_estimators\": [50, 100],\n",
    "    \"clf__max_depth\": [None, 3, 5],\n",
    "    \"clf__min_samples_split\": [1.0, 0.3, 0.5],\n",
    "    \"clf__min_samples_leaf\": [1, 2],\n",
    "    \"clf__max_leaf_nodes\": [None, 5]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "    grid_search.fit(train_data, train_labels)\n",
    "    print(\"Grid Search with RandomForest:\\n\")\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    # Refit an estimator using the best found parameters on the whole dataset.\n",
    "    # The refitted estimator is made available at the best_estimator_attribute and \n",
    "    # permits using predict directly on this GridSearchCV instance.\n",
    "    predictions = grid_search.predict(test_data)\n",
    "    print('Accuracy:', accuracy_score(test_labels, predictions))\n",
    "    print('Precision:', precision_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('Recall:', recall_score(test_labels, predictions, pos_label='pos'))\n",
    "    print('F1_score:', f1_score(test_labels, predictions, pos_label='pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Conclusion\n",
    "Overall, performing Grid Search on the classifiers with their respective parametes help in tuning the performance and improvement is generally observed. The overall best classifier is <br>\n",
    "Grid Search with SVM:<p>\n",
    "\n",
    "Best score: 0.872<br>\n",
    "Best parameters set:<br>\n",
    "clf__C: 10<br>\n",
    "clf__gamma: 0.5<br>\n",
    "clf__kernel: 'rbf'<br>\n",
    "Accuracy: 0.93<br>\n",
    "Precision: 0.9387755102040817<br>\n",
    "Recall: 0.92<br>\n",
    "F1_score: 0.9292929292929293<br>\n",
    "\n",
    "Initially, I wanted to input more different values for parameters and parameters for the classifiers for GridSearch. I also wanted to tune the parameters for the vectors. However, my notebook kept hanging and I had to limit the candidates for different combinations for both classifiers and vectors. If there is enough computing power and time, the classifier models can be further enhanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
